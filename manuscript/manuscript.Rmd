---
title: "Meta-Analysis of the 'Ironic' Effects of Intergroup Contact"
header: "'IRONIC' EFFECTS META-ANALYSIS"
keywords: intergroup contact, meta-analysis, perceived discrimination, collective action, policy support
bibliography: references.bib
csl: apa.csl
nocite: | 
  @19, @45, @46, @91, @93, @244, @284, @286, @303, @322, @324, @325, @336, @401, @414, @423, @480, @609, @703, @733, @783, @789, @803, @813, @823, @829, @830, @856, @893, @894, @933, @956, @1020, @1042, @1045, @1114, @1163, @1221, @1248, @1376, @1386, @1395, @1407, @1411, @1412, @1494, @1525, @1549, @1576, @1614, @1658, @1695, @1743, @1762, @1807, @1850, @1891, @1914, @1949, @1966, @1993, @2001, @2023, @2033, @2075, @2257, @2309, @2333, @2341, @2375, @2380, @2381, @2382, @2383, @2385, @2391, @2392, @2394, @2395, @2396, @2397, @2398, @2399, @3000, @3005, @3051, @3054, @3060, @3134, @3196, @3201, @3205, @4000, @4001, @4002, @4003, @4004, @4005, @bracegirdle_disentangling_2022, @sengupta_protect_unpublished, @osf_repository
abstract: 
  Growing evidence suggests that intergroup contact, psychology’s most-researched paradigm for reducing prejudice, has the ‘ironic’ effect of reducing support for social change in disadvantaged groups. We conducted a preregistered meta-analytic test of this effect across `r with(dplyr::distinct(readRDS("../data/dl.rds"), sample, id, n), numform::f_comma(dplyr::n_distinct(id)))` studies with `r with(dplyr::distinct(readRDS("../data/dl.rds"), sample, id, n), numform::f_comma(length(sample)))` samples of `r with(dplyr::distinct(readRDS("../data/dl.rds"), sample, id, n), numform::f_comma(sum(n)))` disadvantaged-group members. As predicted, intergroup contact was, on average, associated with less perceived injustice (`r with(readRDS("../results/results_preregistered_analyses.rds"), paste0("$r = ", numform::f_num(median(r_mean[x_var == "ic" & y_var == "pi"]), digits = 2), "$"))`), collective action (`r with(readRDS("../results/results_preregistered_analyses.rds"), paste0("$r = ", numform::f_num(median(r_mean[x_var == "ic" & y_var == "ca"]), digits = 2), "$"))`), and support for reparative policies (`r with(readRDS("../results/results_preregistered_analyses.rds"), paste0("$r = ", numform::f_num(median(r_mean[x_var == "ic" & y_var == "ps"]), digits = 2), "$"))`). However, these associations were small, variable, and consistent with alternative explanations. Across outcomes, `r with(readRDS("../results/results_for_abstract.rds"), paste0(round(min(p_pred)*100), "--", round(max(p_pred)*100), "\\%"))` of studies found *positive* associations with intergroup contact. Moderator analyses explained about a third of the between-sample variance, showing that, at least for perceived injustice, associations with intergroup contact were most consistently negative in studies that measured direct, qualitatively positive contact among adults. We also found evidence for an alternative explanation for the apparent ‘ironic’ effects of intergroup contact as, after controlling for the positive association of negative contact with support for social change, positive contact was no longer associated with any of the outcomes. We close by discussing strengths and limitations of the available evidence and by highlighting open questions about the relationship between intergroup contact and support for social change in disadvantaged groups.
output:
  pdf_document:
    latex_engine: pdflatex
    keep_tex: yes
    template: apa-template.tex
---

```{r setup, include = FALSE}

  # Load packages
  library(tidyverse); library(tidybayes); library(numform); library(glue)

  # Functions
  r_to_z <- function(r) 0.5 * log( (1 + r) / (1 - r) )
  z_to_r <- function(z) ( exp(2 * z) - 1 ) / ( exp(2 * z) + 1 )

  # knitr options
  knitr::opts_chunk$set(echo = FALSE)

```

It is ironic that psychology’s most-researched paradigm for reducing prejudice—intergroup contact—should hinder, rather than help, social change. Hundreds of studies have confirmed that intergroup contact is associated with less negative feelings toward outgroup members [for a meta-analysis, see @pettigrew_meta-analytic_2006]. Most of these studies have focused on advantaged-group members' contact experiences with disadvantaged-group members [@tropp_relationships_2005], guided by the idea that reducing advantaged-group members' prejudice will prevent interpersonal discrimination. Reducing prejudice, however, is rarely enough to overcome institutional and structural discrimination. Instead, as the 2020 Black Lives Matter protests have shown, social change often requires political mobilization by the disadvantaged. Critics have argued that, by fostering harmony and reducing conflict, intergroup contact might distract disadvantaged-group members from the injustice they face and, thereby, undermine their motivation for social change [@dixon_beyond_2005; @reicher_rethinking_2007; @brown_strategic_2003]. By reducing disadvantaged-group members' opposition to injustice, intergroup contact might thus have the 'ironic' [@813], 'sedative' [@284], or 'paradoxical' [@336] effect of hindering social change.

Supporting this argument, initial studies provided evidence that contact with advantaged-group members reduces disadvantaged-group members' perceptions of injustice [@813], collective action [@284], and support for reparative policies [@1386]. Others, however, have pointed to conflicting evidence [@1762] and argued that intergroup contact might instead make discrimination more salient and, thereby, increase disadvantaged-group members' support for social change [@pettigrew_recent_2011]. In the decade since the initial studies, many more studies have examined the relationship between intergroup contact and support for social change in disadvantaged groups. We present a systematic review and meta-analysis of this growing literature to evaluate the evidence for and against the 'ironic' effects of intergroup contact.

## Why Intergroup Contact Might Reduce Support for Social Change

Researchers have put forward three hypotheses about how intergroup contact might reduce support for social change in disadvantaged groups.

Perceived injustice—that is, perceiving unjust group-based deprivation or discrimination against a disadvantaged ingroup—is a prerequisite to instigating social change [@van_zomeren_toward_2008]. Researchers have argued that positive contact with advantaged groups could contradict perceptions of personal discrimination and, thereby, make group discrimination appear less plausible [@336]. Positive contact could further reduce perceived injustice by emphasizing commonalities over differences [@813] and by motivating disadvantaged-group members to adopt system-justifying ideologies [@1695]. To the extent that it reduces perceived injustice, intergroup contact reduces support for social change.

Collective action is any action directed at improving the conditions of the disadvantaged ingroup [@wright_responding_1990]. Collective action is crucial to achieving social change because advantaged-group members rarely give up their advantages without sustained pressure from disadvantaged-group members [@blumer_race_1958; for a review, see @dixon_beyond_2012]. Researchers have argued that intergroup contact could discourage disadvantaged-group members from engaging in collective action by diminishing their perceived discrimination [@1743], by reducing the perceived threat from the advantaged outgroup [@1248], by blurring boundaries between the disadvantaged ingroup and the advantaged outgroup [@813], by reducing negative attitudes toward the advantaged outgroup [@wright_struggle_2009], and by quelling their anger  [@2309; @2375]. To the extent that it discourages collective action, intergroup contact reduces support for social change.

Reparative policies (e.g., affirmative action) can be effective means to reduce social inequality. Disadvantaged-group members, who stand to benefit from their implementation, are important advocates for these policies. Researchers have argued that intergroup contact could diminish disadvantaged-group members’ support for redistributive policies by creating sympathy for advantaged-group members [@1386], by fostering positive outgroup attitudes and reducing attention to inequality [@813], and by increasing their endorsement of system-justifying ideologies [@1695]. To the extent that it diminishes support for redistributive policies, intergroup contact reduces support for social change.

To summarize, intergroup contact might hinder social change by reducing disadvantaged-group members' perceived injustice, discouraging them from engaging in collective action, and diminishing their support for reparative policies.

## Why Intergroup Contact Might *not* Reduce Support for Social Change

Others have, however, argued that intergroup contact might *not* reduce support for social change and, in some circumstances, might even *increase* support for social change in disadvantaged groups.

Some studies found evidence that intergroup contact is associated with more, not less, support for social change in disadvantaged groups. @1762 found that Inuit who had more exposure to non-indigenous Canadians perceived greater discrimination against their group than Inuit who lived in relative isolation. Similarly, researchers found that, among members of various disadvantaged groups, intergroup contact was associated with perceiving greater discrimination against the disadvantaged ingroup [@93], perceiving status differences between the advantaged outgroup and disadvantaged ingroup to be less legitimate [@3196], and being more willing to engage in collective action [@93; @3196; @4004]. These findings align with the argument, based in relative deprivation theory [@smith_relative_2012], that contact with the advantaged provides an opportunity for the disadvantaged to recognize their relative disadvantage and, thereby, can motivate the disadvantaged to support social change [see @pettigrew_recent_2011; @1762].

Other researchers have put forward alternative explanations for the apparent 'ironic' effects of intergroup contact. Whereas previous studies had focused on positive contact experiences, recent studies considered both positive and negative contact experiences as predictors of support for social change. These studies [@2309; @956] found negative contact with advantaged-group members to be associated with greater perceived discrimination and stronger collective action intentions. This research suggests that negative contact can motivate disadvantaged-group members to support social change. @956 further found that, first, disadvantaged-group members who have more positive contact also tend to have less negative contact and, second, positive contact is not associated with perceived discrimination or collective action after controlling for negative contact. Based on these findings, @956 argued that the mobilizing effect of negative contact could be an alternative explanation for the negative relationship between positive contact and support for social change observed in prior studies.

Another alternative explanation for the apparent 'ironic' effects of intergroup contact centers on intragroup contact. Whereas most studies focused on contact with the advantaged outgroup, some studies examined contact with the disadvantaged ingroup as a predictor of support for social change. @levin_ethnic_2006 found that, among minority-group college students, ingroup friendship predicted perceived discrimination 1–2 years later. @sengupta_ingroup_2015 found ingroup contact to be associated with decreased endorsement of system-justifying beliefs and increased support for reparative policies benefiting the disadvantaged ingroup [see also @1695]. These studies suggest that contact with other ingroup members can motivate disadvantaged-group members to support social change. As outgroup contact places limits on how much ingroup contact a person can have [@pfister_contact_2020], disadvantaged-group members who have more outgroup contact can be expected to have less ingroup contact. Based on these observations, one might argue that the mobilizing effect of ingroup contact could be an alternative explanation for the negative association between outgroup contact and support for social change observed in prior studies. 

To summarize, intergroup contact might increase, not decrease, support for social change in disadvantaged groups and the apparent 'ironic' effects might be based on spurious relationships between (positive) intergroup contact and support for social change.

## Purpose of the Present Study

As societies are becoming more diverse, there are more opportunities for members of different groups to come in contact with each other. Psychologists disagree about what this means for disadvantaged-group members' awareness of and opposition to social injustice. On the one hand, researchers have argued that intergroup contact might reduce disadvantaged-group members' perceived injustice, discourage them from engaging in collective action, and diminish their support for reparative policies. On the other hand, researchers have argued that intergroup contact might not reduce, or even increase, support for social change in disadvantaged groups. Settling this debate is important both because intergroup contact is a promising means of reducing prejudice [@pettigrew_meta-analytic_2006] and because political mobilization by the disadvantaged is often crucial for achieving social change [see, for example, @mazumder_persistent_2018]. 

As a result of two recent developments, there is now an emerging consensus that, in line with the former argument, intergroup contact has the 'ironic' effect of undermining support for social change in disadvantaged groups. First, a large-scale preregistered multi-country study provided the most comprehensive evidence to date that contact with advantaged groups correlates with less support for social change in disadvantaged groups [@3054]. Second, several narrative reviews of the growing evidence for the 'ironic' effects of intergroup contact have been published [@hassler_intergroup_2021; @macinnis_extending_2019; @mckeown_contact_2017]. Narrative reviews do not, however, include all relevant studies and do not synthesize the, sometimes conflicting, findings of different studies. We present the first systematic review and meta-analysis of the relationship between intergroup contact and support for social change in disadvantaged groups. To test the hypothesized 'ironic' effects of intergroup contact, we evaluate the evidence that contact with advantaged-group members reduces disadvantaged-group members' perceived injustice, collective action, and support for reparative policies.

Our first objective was to systematically review the available evidence and to evaluate its strengths and limitations. Our second objective was to synthesize the available evidence to establish the direction and magnitude of the relationships between intergroup contact and the three outcomes. Doing so allowed us to determine whether the available evidence supports a negative or positive direct relationship between contact and support for social change and to estimate the strength of this relationship. Our third objective was to estimate and explain the variability of this relationship across study settings, designs, and other potential moderators. For example, we examined whether any effects were confined to Western, Educated, Industrialized, Rich, Democratic (WEIRD) countries, the cultural context of most psychological research [@henrich_weirdest_2010]. Our fourth objective was to assess how robust the available evidence was to publication bias. Our final objective was to explore the available evidence for negative contact and ingroup contact as alternative explanations of the apparent 'ironic' effects of intergroup contact.

In pursuing these objectives, we focus on the direct relationships of intergroup contact with perceived injustice, collective action, and support for reparative policies in disadvantaged groups. We do not consider indirect and interaction effects or the effects of imagined, extended, or parasocial contact. Further, while the argument for the 'ironic' effects of intergroup contact is part of a broader critique of the prejudice reduction model of social change [for a review, see @dixon_beyond_2012], our meta-analysis tests the narrower hypothesis whether intergroup contact reduces support for social change in disadvantaged groups.

# Method

## Open Practices Statement

We prepared a protocol in accordance with the PRISMA-P statement [@moher_preferred_2015] and preregistered it on the Open Science Framework.^[[https://osf.io/ryuev/](https://osf.io/ryuev/)] Preregistration precludes undisclosed flexibility in study selection, outcome selection, and other decisions that influence effect size estimates—and thus prevents confirmation bias from determining the conclusions of a meta-analysis [@lakens_reproducibility_2016]. We report deviations from our preregistered protocol at the end of the Method section. We make data, analysis scripts, and the fully reproducible manuscript available online.^[[https://osf.io/w5tqv/](https://osf.io/w5tqv/)]

## Eligibility Criteria

As preregistered, we considered all quantitative studies that included participants of a relatively disadvantaged group (see *Types of Participants*), that manipulated or measured intergroup contact with a relatively advantaged group (see *Types of Predictor Variables*), and that measured one or more of the following outcomes: perceptions or expectations of injustice, collective action intentions and behaviours, and/or support for policies that benefit or harm the participants’ ingroup (see *Types of Outcome Variables*).

### Types of Participants

We included studies with participants whose ingroup is disadvantaged (in terms of status, power, or resources) relative to the outgroup they have (or report to have) contact with.

### Types of Predictor Variables

We included studies if they measured or manipulated the quantity of, quality of, and opportunity for contact with members of outgroups that are relatively advantaged compared to the participants’ ingroup. We considered opportunity for contact, as it is a potential precursor to and proxy for face-to-face contact, but not imagined or extended contact. Similarly, we included studies that measured intergroup contact indirectly by, for example, asking what proportion of someone’s friends were *not* from the participants’ ingroup.

### Types of Outcome Variables

***Perceived Injustice.*** We included studies that measured perceptions that one is discriminated against because of one’s group membership, that one’s group faces discrimination in society, that one’s group is relatively deprived compared to other groups, or that the deprivation and/or discrimination faced by one’s group is unjust and illegitimate. We also considered expectations of fair treatment as the reverse of perceived injustice. We included studies that measured personal or group discrimination or both.

***Collective Action.*** We included studies that measured observed, reported, or intended engagement in any action aimed at improving the position of the participants’ ingroup in society. This included participating in protests, signing petitions, and any other form of violent or nonviolent collective action.

***Policy Support.*** We included studies that measured support for (or opposition to) policies and initiatives designed to improve the position of the participants’ ingroup in society, for example, affirmative action policies.


## Search Strategy

```{=latex}
\begin{figure*}[t!]
\centering
\caption{Flow diagram illustrating the preregistered search strategy, study selection, and data collection}
\includegraphics[scale=1]{../figures/figure-1}
\label{fig:f1}
\end{figure*}
```

As preregistered, we searched titles, abstract, and keywords for relevant terms in four electronic databases. We searched for relevant articles in the *Scopus* and *PsycINFO* databases. We searched for gray literature in the *ProQuest Dissertations and Theses* database. We used similar non-exclusive search terms for all databases (see SOM). We searched databases on April 1, 2019 and again on April 1, 2020. We exported records and relevant metadata from each database. We removed duplicates using the *revtools* R package [@westgate_revtools:_2019]. 

To find unpublished studies, we sent a call to the mailing lists of several professional organizations (see SOM). We also advertised on social media and at relevant conferences. We directed researchers to an online survey in which they answered questions about the eligibility of their unpublished research and, if the research was eligible, provided data on moderator variables and effect sizes. We also contacted experts in the field, asking for unpublished research and other studies we might have missed.

In addition, we used the *Scopus* citation database to find records that cited at least one of the published articles included in the meta-analysis or at least one of three relevant review articles [@dixon_beyond_2012; @reicher_rethinking_2007; @wright_struggle_2009]. This search resulted in 2,075 records. Of these, we focused on 145 records that cited at least three eligible studies or relevant reviews and looked for eligible studies that were not among those from our original search.

## Study Selection

As preregistered, we selected studies in three stages. First, we screened records based on their title, abstract, and keywords. We refined our coding strategy over three random samples of 100 records until we achieved acceptable inter-rater agreement ($\kappa_1 = .56$, $\kappa_2 = .60$, $\kappa_3 = .79$). We then divided the remaining records between the two authors. For each record, one of the authors coded whether the record met the eligibility criteria (yes, maybe, no), or whether it was a relevant review article. We kept all records coded as “yes” or “maybe”. Second, both authors reviewed each of the full-text manuscripts from the previous stage and coded whether any study or sample in the manuscript fulfilled the preregistered eligibility criteria ($\kappa = .75$). Third, we resolved any disagreements (by consensus) and excluded ineligible records.

## Data Collection

### Effect Sizes

From all eligible records, we extracted correlation coefficients ($r$) as the relevant measure of effect size and extracted sample sizes ($n$) to calculate standard errors for each sample’s correlation coefficients. When provided, we copied correlation coefficients from the text or tables. When other effect-size measures were provided, we converted them to correlation coefficients using common conversion formulas [@borenstein_introduction_2009]. When effect sizes were not provided, we attempted to contact the authors to obtain the relevant effect sizes. We did not contact authors for studies that were more than twenty years old as we considered it unlikely that authors still had access to the underlying data. When we could not extract or obtain an effect size for a study or sample, we either imputed missing correlation coefficients from standardized beta coefficients [@peterson_use_2005] if reported or excluded the study or sample if not.

### Outcome Selection

We collected effect sizes for all relationships between eligible predictor and outcome variables. When more than one eligible measure was reported, we extracted effect sizes for all of them. As preregistered, we also extracted effect sizes for negative contact, ingroup contact, group identification, and outgroup attitudes.

When a study reported effect sizes for more than one measure of intergroup contact, we prioritized the predictor variable in the preregistered analyses that measured the most intense or intimate form of contact. As preregistered, we used the following ranking: cross-group friendship > quality of contact/positive contact > quantity of contact > opportunity for contact. When it was unclear which of several predictor variables measured the most intense form of contact, we combined and averaged effect sizes.

When a study reported effect sizes for more than one measure of one of the three outcome variables, we selected effect sizes for the preregistered analyses as follows: For perceived injustice, we prioritized the measure closest to perceptions of injustice against the participants’ ingroup (rather than against the participants themselves); when it was ambiguous which measure that was, we combined and averaged effect sizes across outcome measures. For collective action, we prioritized the measure that was the primary focus of the reported analyses; otherwise, we combined and averaged effects sizes across outcome measures. For policy support, we combined and averaged effect sizes for all policies designed to improve the position of the participants’ ingroup in society.

Some study designs resulted in more than one effect size for the same measure: When a longitudinal study reported results from more than two waves, we prioritized effect sizes spanning the inter-survey interval closest to one year. If a longitudinal study reported results from more than two waves and spanned multiple years, we combined and averaged effect sizes from each one-year inter-survey interval. In the preregistered analyses, we included the cross-lagged partial correlation between the relevant predictor variable (at time 1) and outcome variable (at time 2) controlling for initial levels of the outcome variable (at time 1). When an experimental or quasi-experimental study reported comparisons between more than two conditions, we prioritized the effect size that compared two conditions that most closely resembled generic contact and no-contact conditions.

```{=latex}
\begin{figure*}
\centering
\caption{Overview of the relevant literature}
\includegraphics[scale=1]{../figures/figure-2}
\caption*{\textit{Note.} \textbf{A} Map of all countries included in the meta-analysis with combined sample sizes. \textbf{B} Proportion of eligible samples in each category as well as the absolute number of samples in each category.}
\label{fig:f2}
\end{figure*}
```

### Potential Moderators

In addition to extracting and selecting effect sizes for the preregistered analyses, we collected data on a broad range of potential moderators. All moderators that required subjective assessments were coded by both authors. We calculated inter-rater agreement (Cohen’s $\kappa$) and resolved all disagreements by consensus.

***Study Setting.*** For each sample, we recorded in what country (or countries) the data was collected ($\kappa = .97$) and what the disadvantaged ingroup and the advantaged outgroup were. We categorized each sample’s setting according to whether the source of the groups’ relative inequality was long-term migration (e.g., Asian Americans), short-term  migration (e.g., international students), slavery (e.g., Black Americans), colonization (e.g., Māori, Black South Africans), religion, caste, sexual/gender identity, or another distinction ($\kappa = .85$; see SOM for details).

***Study Design.*** We categorized each study as either correlational and cross-sectional, correlational and longitudinal, quasi-experimental, experimental, an intervention, or other ($\kappa = .85$). We categorized each sample as either a student convenience sample, a non-student convenience sample, a probability or representative sample, or another kind of sample ($\kappa = .73$). We categorized the age group(s) in each sample as children ($\leq 12$ years), adolescents (13–18 years), or adults ($\geq 18$ years; $\kappa = .64$).

***Study Intention.*** We coded whether or not each study was conducted with the intention to examine the effects of intergroup contact on one or more of the three outcome measures ($\kappa = .48$). We did not achieve acceptable inter-rater agreement in our initial coding. After refining our coding criteria, we re-coded all studies by consensus.

***Publication status.*** For each study, we coded whether it was published, unpublished, or an unpublished dissertation based on the information source from which we obtained it.

***Predictor Variables.*** For each measure of intergroup contact, we coded whether it assessed contact with the specific advantaged outgroup of interest directly—or whether it assessed contact indirectly by, for example, asking what proportion of someone’s friends were not from the participants’ ingroup or what proportion of residents in someone’s neighborhood were from the relevant outgroup ($\kappa = .82$). In addition, we coded whether each predictor variable assessed direct, qualitatively positive intergroup contact by, for example, measuring contact quality or cross-group friendship with the advantaged outgroup($\kappa = .82$).^[We thank John Dixon for his suggestion to consider the distinction between contact quantity and quality in our analyses. As we added this moderator during peer review and as doing so changed the results of our moderator analyses, we report our original findings in the SOM.]

***Outcome Variables.*** For each measure of perceived injustice, we coded whether it refered to specific instances of discrimination, to a more general perception of discrimination, or to both ($\kappa = .67$) and whether it assessed personal discrimination, group discrimination, or both ($\kappa = .84$).

***Cultural Distance.*** We also used the index developed by @muthukrishna_beyond_2020, where available, to quantify each country’s cultural distance from the United States, which represents the cultural context of most psychological research [@henrich_weirdest_2010].

## Analysis Strategy

### Preregistered Analyses

We transformed correlation coefficients to Fisher’s $z$ which is unbounded and has a normal sampling distribution: \begin{align*} 
z & = \frac{1}{2} \ln\left(\frac{1 + r}{1 - r}\right) \\ \sigma & = \frac{1}{\sqrt{n - 3}} \end{align*} where $r$ is the sample correlation coefficient, $z$ is the transformed effect size, $n$ is the sample size, and $\sigma$ is the standard error of the transformed effect size.

We estimated effect sizes with Bayesian random-effects meta-analysis models, using the *RStan* package [@stan_development_team_rstan:_2020] for the R programming language [@r_version_2021], which modeled the *z*-transformed correlation coefficients with a normal likelihood function: \begin{align*} z_{ij} &\sim \text{Normal}(\theta_{ij}, \sigma_{ij}) \\ \theta_{ij} &= \begin{cases} \mu + \beta_j\tau_J & \text{if } I_j = 1 \\ \mu + \beta_j\tau_J + \beta_i\tau_I & \text{if } I_j > 1 \end{cases} \\ \end{align*} where $z_{ij}$ is the observed effect size in sample $i$ of study $j$, $\sigma_{ij}$ is the sample standard error, and $\theta_{ij}$ is the estimated effect size. We estimated $z_{ij}$ as a function of the mean effect size $\mu$ and of two varying (random) intercepts, $\beta_i$ and $\beta_j$, with the corresponding standard deviations, $\tau_I$ and $\tau_J$. We used the non-centered parameterization to model the random effects. For studies that contained only one sample ($I_j = 1$), we only included $\beta_j\tau_J$, the study-wise deviation from the mean effect size $\mu$. For studies that contained more than one sample ($I_j > 1$), we also estimated $\beta_i\tau_I$, the sample-wise deviation from the study-specific effect size.

Models assigned weakly informative prior distributions to all parameters. The prior distribution for the mean effect size, $\mu \sim \text{Normal}(0, 0.31605)$, was centered around 0 and concentrated 50% of the most plausible values between $r = -.21$ and $r = .21$. We focus on $|r| = .21$ because it corresponds to the mean effect size observed in both Pettigrew and Tropp’s [-@pettigrew_meta-analytic_2006] meta-analysis of the contact literature and Richard et al.’s [-@richard_one_2003] meta-analysis of effect sizes across a century of social-psychological research. The prior distribution for the standard deviation of random effects, $\tau \sim \text{Half-Cauchy}(0, 0.3)$, allocated 30% of plausible values below $\tau = 0.15$ and had a wide tail. We focus on $\tau = 0.15$ because it corresponds to the standard deviations observed in both Pettigrew and Tropp’s [-@pettigrew_meta-analytic_2006] and Richard et al.’s [-@richard_one_2003] meta-analyses. We chose this prior distribution in line with recommendations by Williams et al. (2018).

Bayesian inference involves choosing a likelihood function and prior distributions. A likelihood function links the observed data to one or more model parameters and states how likely the observed data are given different values of said model parameters. Prior distributions state how plausible different values of said model parameters are before considering the observed data. Bayesian inference applies Bayes’ theorem to update prior distributions in light of the observed data to produce posterior distributions. In contrast to *p*-values and confidence intervals, the resulting posterior distributions have a straightforward interpretation as stating how plausible different values of the model parameters are given the observed data.^[For an accessible introduction, see @mcelreath_statistical_2020.] We report point estimates, based on the median of posterior samples, and uncertainty intervals, based on the quantiles of posterior samples, that enclose the 95% most plausible estimates. In addition, we report the posterior probability, based on the proportion of posterior samples below zero, that the mean effect size is negative.

### Other Analyses

We also conducted non-preregistered analyses to estimate to what extent moderator variables explained heterogeneity in the estimated effect sizes, to what extent meta-biases influenced the estimated effect sizes, and to what extent the three outcome variables were associated with two alternative predictor variables, ingroup contact and negative contact.

## Deviations From the Preregistration

Some aspects of the preregistered protocol proved unrealistic, impractical, or underspecified. Therefore, we deviated from the preregistration in the following ways:

1. We preregistered that we would update our search every four months until we would submit the manuscript. This proved unrealistic as the study selection and data collection process for the new studies took almost as long. Instead, we concluded our search of electronic databases on April 1, 2020—that is, before we started analyzing and documenting our findings.

2. We preregistered that we would randomly select 100 records to be screened by both coders to calculate inter-rater agreement. We did not specify, however, what we would do if inter-rater agreement was less than acceptable. We decided to refine our coding strategy over three samples of 100 records until we achieved acceptable agreement.

3. We preregistered that we would use *Google Scholar* to find records citing eligible studies. This proved impractical as *Google Scholar* does not allow the electronic export of citing records. Instead, we used the *Scopus* citation database.

4. We preregistered that we would attempt to contact the authors of *all* papers with missing effect sizes. Instead, we decided to not contact authors for studies published before 2000 as we considered it unlikely that the authors still had access to the data.

5. We preregistered that we would use a Bayesian two-level random-effects meta-analysis model for all preregistered analyses. For the association between policy support and collective action, however, we had only few studies and found that the two-level model did not result in a reliable posterior distribution. Instead, we used a Bayesian one-level random-effects model to estimate that association.

# Results

## Search Results

```{r, include = FALSE}

  # Import data
  dl <- read_rds("../data/dl.rds")
  counts <- read_rds("../figures/figure-1.rds")

```

Figure 1 shows a flow diagram illustrating our search strategy, study selection, and data collection. Our preregistered search strategy returned `r f_comma(counts$n_included[1])` unique records from electronic databases. Of these, we excluded `r f_comma(counts$n_excluded[2])` (`r f_comma(counts$p_excluded[2])`) ineligible records after screening titles, abstracts, and keywords. Of the remaining `r f_comma(counts$n_included[2])` records, we excluded `r f_comma(counts$n_excluded[3])` (`r f_comma(counts$p_excluded[3])`) ineligible records after reviewing full-text manuscripts. We supplemented these records with `r f_comma(counts$unpublished[3])` unpublished studies and `r f_comma(counts$citing[3])` records that cited at least three relevant works. Of `r f_comma(with(counts[3,], database + citing + unpublished))` eligible studies, we had to exclude `r f_comma(counts$n_excluded[4])` (`r f_comma(counts$p_excluded[4])`) studies for which we could not extract or impute any relevant effect size. At each stage, we also excluded studies that used the same data as another study. Our final sample comprised effect sizes from `r paste0("$J = ", with(dl, f_comma(n_distinct(id))), "$")` studies spanning `r paste0("$N = ", with(distinct(dl, id, sample, n), f_comma(sum(n))), "$")` participants in `r paste0("$I = ", f_comma(nrow(distinct(dl, id, sample))), "$")` samples (for a complete list of studies, see SOM).

Figure 2 provides a qualitative overview of the literature. Even though most participants came from studies conducted in India (`r glue('$N = {f_comma(with(distinct(dl, id, sample, n, country), sum(n[country == "India"])))}$')`) and the United States (`r glue('$N = {f_comma(with(distinct(dl, id, sample, n, country), sum(n[country == "USA"])))}$')`; Figure 2a), most samples were collected in North America (`r glue('$I = {f_comma(with(distinct(dl, id, sample, n, continent), length(sample[continent == "North America"])))}$')`) and Europe (`r glue('$I = {f_comma(with(distinct(dl, id, sample, n, continent), length(sample[continent == "Europe"])))}$')`), with few samples from South America and Africa (Figure 2b). Most samples focused on relative inequalities that resulted from long-term migration (`r glue('$I = {f_comma(with(distinct(dl, id, sample, study_setting), length(sample[study_setting == "Long-term migration"])))}$')`), slavery (`r glue('$I = {f_comma(with(distinct(dl, id, sample, study_setting), length(sample[study_setting == "Slavery"])))}$')`), colonization (`r glue('$I = {f_comma(with(distinct(dl, id, sample, study_setting), length(sample[study_setting == "Colonization"])))}$')`), and short-term migration (`r glue('$I = {f_comma(with(distinct(dl, id, sample, study_setting), length(sample[study_setting == "Short-term migration"])))}$')`). With few exceptions, studies used correlational, cross-sectional survey designs. Samples sizes ranged from `r with(distinct(dl, id, sample, n), paste0(f_comma(min(n)), " to ", f_comma(max(n)), " ($\\textit{Mdn} = ", f_comma(median(n)), "$)"))`. Unlike most psychological research, 2 in 5 samples used probability or representative sampling. Of all samples, `r with(distinct(dl, id, sample, study_intention), f_prop2percent(mean(study_intention == "Yes"), digits = 0))` (`r glue('$I = {f_comma(with(distinct(dl, id, sample, n, study_intention), length(sample[study_intention == "Yes"])))}$')`) were collected with the intention to examine the effects of intergroup contact on the outcomes considered in this meta-analysis. Many studies instead examined acculturation processes [@berry_immigration_1997] and measured intergroup contact and perceived injustice without hypothesizing that the former would affect the latter. Together, these observations highlight both limitations and strengths of the empirical literature.

## Preregistered Analyses

```{r, include = FALSE}

  # Summarize results
  results <- read_rds("../results/results_preregistered_analyses.rds") %>% 
    pivot_longer(
      c(r_mean, tau_ii, tau_jj),
      names_to = "parameter",
      values_to = "estimate",
      values_drop_na = TRUE
    ) %>% 
    group_by(x_var, y_var, parameter) %>% 
    summarize(
      I = f_comma(unique(I)),
      J = f_comma(unique(J)),
      N = f_comma(unique(N)),
      median = median(estimate),
      .lower = quantile(estimate, 0.025),
      .upper = quantile(estimate, 0.975),
      p_below = mean(estimate < 0),
      p_above = mean(estimate > 0)
    ) %>% 
    ungroup() %>% 
    mutate(
      across(
        c(median, .lower, .upper), 
        ~f_num(., digits = 2)
      ),
      across(
        c(p_below, p_above), 
        ~case_when(
          . < .001 ~ "$<0.1\\%$",
          . > .999 ~ "$>99.9\\%$",
          TRUE ~ paste0("$", f_num(. * 100, digits = 1), "\\%$")
        )
      ),
      text = case_when(
        parameter == "r_mean" ~ paste0("$r = ", median, ", [", .lower, ", ", .upper, "]$"),
        parameter == "tau_ii" ~ paste0("$\\tau_I = ", median, ", [", .lower, ", ", .upper, "]$"),
        parameter == "tau_jj" ~ paste0("$\\tau_J = ", median, ", [", .lower, ", ", .upper, "]$"),
        TRUE ~ paste0("$", median, ", [", .lower, ", ", .upper, "]$")
      )
    ) %>% 
    select(-median, -.lower, -.upper)

```

```{r, include = FALSE}

  # Set seed (for posterior predictive simulations)
  set.seed(9071118)

  # Simulate posterior predictions
  post_pred <- read_rds("../results/results_preregistered_analyses.rds") %>% 
    filter(x_var == "ic") %>% 
    mutate(
      r_pred = z_to_r(rnorm(n = n(), mean = mu, sd = tau_jj))
    )
  
  # Define functions for power calculations
  p_value <- function(r, n) 2*min(pnorm(0, r_to_z(r), 1/sqrt(n - 3)), 1-pnorm(0, r_to_z(r), 1/sqrt(n - 3)))
  p_value <- Vectorize(p_value)
  n_req   <- function(r) uniroot(function(n) ( 0.05 - p_value(r, n) ), c(3, 1e6))$root
  n_req   <- Vectorize(n_req)
  
  # Summarize posterior predictions
  post_pred <- post_pred %>% 
    group_by(x_var, y_var) %>% 
    summarize(
      r_pred_l80 = quantile(r_pred, 0.10),
      r_pred_u80 = quantile(r_pred, 0.90),
      p_pred_positive = mean(r_pred > 0),
      r_abs = quantile(abs(r_pred), 0.20),
      n_req = n_req(r_abs)
    ) %>% 
    ungroup() %>% 
    mutate(
      across(
        c(r_pred_l80, r_pred_u80),
        ~f_num(., digits = 2)
      ),
      r_abs = paste0("$|r| > ", f_num(r_abs, digits = 3), "$"),
      n_req = f_comma(ceiling(n_req))
    )

```

As preregistered, we ran three random-effects meta-analysis models, one for each outcome variable. Figure 3 shows posterior distributions from these analyses.

```{=latex}
\begin{figure*}[t!]
\centering
\caption{Posterior distributions from the preregistered random-effects meta-analysis models}
\includegraphics[scale=1]{../figures/figure-3}
\caption*{\textit{Note.} \textbf{A} Posterior distributions for the mean correlation coefficients, highlighting the proportion of posterior samples for which $r_\text{mean} < 0$. \textbf{B} Posterior predictive distributions of study-wise correlation coefficients, highlighting the 80\% most common effect sizes, with point estimates for the correlation coefficients for all studies in the sample.}
\label{fig:f3}
\end{figure*}
```

```{r, include = FALSE}
pi_results <- results %>% filter(x_var == "ic", y_var == "pi")
```

***Perceived Injustice.*** Across `r unique(pi_results$N)` participants from `r unique(pi_results$I)` samples in `r unique(pi_results$J)` studies, we found strong evidence for a weak negative association (`r pi_results$text[pi_results$parameter == "r_mean"]`) between intergroup contact and perceived injustice, with `r pi_results$p_below[pi_results$parameter == "r_mean"]` of posterior samples for the mean correlation coefficient falling below zero. We found evidence that correlation coefficients varied across studies (`r pi_results$text[pi_results$parameter == "tau_jj"]`) and across samples within studies  (`r pi_results$text[pi_results$parameter == "tau_ii"]`). Based on these analyses, we predicted that 80\% of studies would result in correlation coefficients between `r post_pred$r_pred_l80[post_pred$y_var == "pi"]` and `r post_pred$r_pred_u80[post_pred$y_var == "pi"]` and that `r f_prop2percent(with(post_pred, p_pred_positive[y_var == "pi"]), digits = 0)` of studies would find a *positive* correlation between intergroup contact and perceived injustice. Our analyses suggested that researchers would need sample sizes of at least `r post_pred$n_req[post_pred$y_var == "pi"]` participants to find significant associations ($\alpha = .05$, two-sided) in 80\% of their studies.^[Sample sizes are based on posterior predictions which implied that, for 80\% of studies, the absolute correlation coefficient would be `r post_pred$r_abs[post_pred$y_var == "pi"]` for perceived injustice, `r post_pred$r_abs[post_pred$y_var == "ca"]` for collective action, and `r post_pred$r_abs[post_pred$y_var == "ps"]` for policy support.]

```{r, include = FALSE}
ca_results <- results %>% filter(x_var == "ic", y_var == "ca")
```

***Collective Action.*** Across `r unique(ca_results$N)` participants from `r unique(ca_results$I)` samples in `r unique(ca_results$J)` studies, we found some evidence for a weak negative association (`r ca_results$text[ca_results$parameter == "r_mean"]`) between intergroup contact and collective action, with `r ca_results$p_below[ca_results$parameter == "r_mean"]` of posterior samples for the mean correlation coefficient falling below zero. We found evidence that correlation coefficients varied across studies (`r ca_results$text[ca_results$parameter == "tau_jj"]`) and across samples within studies  (`r ca_results$text[ca_results$parameter == "tau_ii"]`). Based on these analyses, we predicted that 80\% of studies would result in correlation coefficients between `r post_pred$r_pred_l80[post_pred$y_var == "ca"]` and `r post_pred$r_pred_u80[post_pred$y_var == "ca"]` and that `r f_prop2percent(with(post_pred, p_pred_positive[y_var == "ca"]), digits = 0)` of studies would find a *positive* correlation between intergroup contact and collective action. Our analyses suggested that researchers would need sample sizes of at least `r post_pred$n_req[post_pred$y_var == "ca"]` participants to find significant associations ($\alpha = .05$, two-sided) in 80\% of their studies.

```{r, include = FALSE}
ps_results <- results %>% filter(x_var == "ic", y_var == "ps")
```

***Policy Support.*** Across `r unique(ps_results$N)` participants from `r unique(ps_results$I)` samples in `r unique(ps_results$J)` studies, we found evidence for a weak negative association (`r ps_results$text[ps_results$parameter == "r_mean"]`) between intergroup contact and policy support, with `r ps_results$p_below[ps_results$parameter == "r_mean"]` of posterior samples for the mean correlation coefficient falling below zero. We found evidence that correlation coefficients varied across studies (`r ps_results$text[ps_results$parameter == "tau_jj"]`) and, to a lesser extent, across samples within studies  (`r ps_results$text[ps_results$parameter == "tau_ii"]`). Based on these analyses, we predicted that 80\% of studies would result in correlation coefficients between `r post_pred$r_pred_l80[post_pred$y_var == "ps"]` and `r post_pred$r_pred_u80[post_pred$y_var == "ps"]` and that `r f_prop2percent(with(post_pred, p_pred_positive[y_var == "ps"]), digits = 0)` of studies would find a *positive* correlation between intergroup contact and policy support. Our analyses suggested that researchers would need sample sizes of at least `r post_pred$n_req[post_pred$y_var == "ps"]` participants to find significant associations ($\alpha = .05$, two-sided) in 80\% of their studies.

```{r, include = FALSE}
pi_ca_results <- results %>% filter(x_var == "pi", y_var == "ca", parameter == "r_mean")
pi_ps_results <- results %>% filter(x_var == "pi", y_var == "ps", parameter == "r_mean")
ca_ps_results <- results %>% filter(x_var == "ca", y_var == "ps", parameter == "r_mean")
```

As preregistered, we ran another three random-effects meta-analysis models to estimate the relationships between the three outcome variables. As we were not interested in the direction of these relationships, we used cross-sectional correlation coefficients as effect sizes for longitudinal studies. Across `r pi_ca_results$N` participants from `r pi_ca_results$I` samples in `r pi_ca_results$J` studies, we found evidence for a moderate association (`r pi_ca_results$text`) between perceived injustice and collective action. Across `r pi_ps_results$N` participants from `r pi_ps_results$I` samples in `r pi_ps_results$J` studies, we found evidence for a moderate association (`r pi_ps_results$text`) between perceived injustice and policy support. Across `r ca_ps_results$N` participants from `r ca_ps_results$I` samples in `r ca_ps_results$J` studies, we found evidence for a moderate association (`r ca_ps_results$text`) between collective action and policy support.

### Robustness Checks

```{r, include = FALSE}

  # Summarize prior choice results
  d_priors <- read_rds("../results/results_robustness_checks_priors.rds") %>% 
    group_by(y_var, prior) %>% 
    median_qi(d_r_mean) %>% 
    mutate(
      across(c(d_r_mean, .lower, .upper), ~f_num(., digits = 2)),
      text = paste0("$\\Delta r = ", d_r_mean, ", [", .lower, ", ", .upper, "]$")
    )

```

```{r, include = FALSE}

  # Calculate Mean Absolute Deviation (MAD)
  mad_loo <- read_rds("../results/results_robustness_checks_loo.rds") %>% 
    group_by(.draw, y_var) %>% 
    summarize(mad_loo = mean(ae_loo)) %>% 
    group_by(y_var) %>% 
    median_qi(mad_loo) %>% 
    mutate(
      across(c(mad_loo, .lower, .upper), ~f_num(., digits = 2)),
      text = paste0("$\\textit{MAD} = ", mad_loo, ", [", .lower, ", ", .upper, "]$")
    )

  # Leave out most influential studies
  d_loo <- read_rds("../results/results_robustness_checks_loo.rds") %>% 
    group_by(y_var, id) %>%
    median_qi(e_loo) %>% 
    group_by(y_var) %>% 
    top_n(n = 1, wt = abs(e_loo)) %>% 
    mutate(
      across(c(e_loo, .lower, .upper), ~f_num(., digits = 2)),
      text = paste0("$\\Delta r = ", e_loo, ", [", .lower, ", ", .upper, "]$")
    )

```

As preregistered, we conducted two kinds of robustness checks. First, we assessed to what extent our findings were sensitive to choosing narrower, $\mu \sim \text{Normal}(0, 0.1)$, or wider, $\mu \sim \text{Normal}(0, 1)$, prior distributions. Choosing narrower or wider prior distribution did not affect mean effect size estimates for perceived injustice (`r d_priors$text[d_priors$y_var == "pi" & d_priors$prior == "N(0, 0.1)"]` and `r d_priors$text[d_priors$y_var == "pi" & d_priors$prior == "N(0, 1.0)"]`), collective action (`r d_priors$text[d_priors$y_var == "ca" & d_priors$prior == "N(0, 0.1)"]` and `r d_priors$text[d_priors$y_var == "ca" & d_priors$prior == "N(0, 1.0)"]`), and policy support (`r d_priors$text[d_priors$y_var == "ps" & d_priors$prior == "N(0, 0.1)"]` and `r d_priors$text[d_priors$y_var == "ps" & d_priors$prior == "N(0, 1.0)"]`). Second, we assessed to what extent our findings were sensitive to including or excluding influential studies by repeating the preregistered analyses $J$ times while leaving out one of $J$ studies each time and by calculating the mean absolute difference (*MAD*) for the estimated mean effect size across left-out studies. For perceived injustice (`r mad_loo$text[mad_loo$y_var == "pi"]`), collective action (`r mad_loo$text[mad_loo$y_var == "ca"]`), and policy support (`r mad_loo$text[mad_loo$y_var == "ps"]`), the *MAD* was small. Leaving out the most influential study, for example, did not change estimates of the mean effect sizes for the three outcomes (`r d_loo$text[d_loo$y_var == "pi"]`; `r d_loo$text[d_loo$y_var == "ca"]`; `r d_loo$text[d_loo$y_var == "ps"]`). These analyses showed that our findings were robust to choosing different prior distributions and to excluding influential studies.

## Moderator Analyses

We conducted three kinds of moderator analyses. As we had insufficient numbers of effect sizes to examine moderators for collective action and policy support, we report results for these outcomes in the SOM.

```{=latex}
\begin{figure*}
\centering
\caption{Estimated effect sizes for the association between intergroup contact and perceived injustice as a function of various categorical moderator variables}
\includegraphics[scale=1]{../figures/figure-4}
\caption*{\textit{Note.} Intervals enclose the 95\% most plausible estimates of the category-specific effect size. Shaded ribbons enclose the 95\% most plausible estimates of the mean effect size from the main analyses. Percentages indicate the estimated between-sample variance explained by each moderator variable.}
\label{fig:f4}
\end{figure*}
```

```{r, include = FALSE}
  
  # Load results
  weird_results <- read_rds("../results/results_cultural_distance.rds")

  # Summarize results
  weird_results <- weird_results %>% 
    group_by(y_var) %>% 
    distinct(.chain, .iteration, .draw, b_x) %>% 
    summarize(
      median = median(b_x),
      .lower = quantile(b_x, 0.025),
      .upper = quantile(b_x, 0.975),
      p = mean(b_x < 0)
    ) %>% 
    mutate(
      across(
        c(.lower, .upper), 
        ~f_pad_zero(f_num(., digits = 2))
      ),
      median = str_replace(f_num(median, digits = 2), "-.", "-0."),
      p_text = case_when(
        p < .001 ~ "$\\Pr (\\beta < 0) < 0.1\\%$",
        p > .999 ~ "$\\Pr (\\beta < 0) > 99.9\\%$",
        TRUE ~ paste0("$\\Pr (\\beta < 0) = ", f_num(p * 100, digits = 1), "\\%$")
      ),
      r_text = paste0("$\\beta = ", median, ", [", .lower, ", ", .upper, "]$"),
      text = paste(r_text, p_text, sep = "; ")
    )

```

```{=latex}

\begin{figure*}
\centering
\caption{Estimated effect size as a function of cultural distance from the United States, with point estimates and uncertainty intervals for each country}
\includegraphics[scale=1]{../figures/figure-5}
\caption*{\textit{Note.} We had data from too few countries to reach firm conclusions about the direction of these associations for perceived injustice (`r with(weird_results, text[y_var == "pi"])`), collective action (`r with(weird_results, text[y_var == "ca"])`), and policy support (`r with(weird_results, text[y_var == "ps"])`).}
\label{fig:f5}
\end{figure*}

\begin{figure*}
\centering
\caption{Results from the random-effects meta-regression tree analysis}
\includegraphics[scale=1]{../figures/figure-6}
\caption*{\textit{Note.} Posterior distributions for the estimated correlation coefficient in each leaf of the meta-regression tree, highlighting the proportion of posterior samples for which $r_\text{mean} < 0$.  S.-T. Migration = Short-Term Migration.}
\label{fig:f6}
\end{figure*}

```

```{r, include = FALSE}

  # Import results from moderator analyses
  R2 <- read_rds("../results/results_categorical_moderator_analyses.rds") %>% 
    mutate(
      R2 = map_dbl(R2, ~median(.$R2)), 
      R2 = glue("$R^2 = {f_num(R2 * 100, digits = 0)}\\%$")
    ) %>% 
    filter(y_var == "pi") %>% 
    select(moderator, R2)

  # Import results from moderator analyses
  meta_cart <- read_rds("../results/results_exploratory_moderator_analyses.rds") %>% 
    group_by(kk, ic_quality, age, study_setting) %>% 
    summarize(
      r_kk = glue("$r = {f_num(median(r), digits = 2)}, [{f_num(quantile(r, 0.025), digits = 2)}, {f_num(quantile(r, 0.975), digits = 2)}]$"),
      p_kk = mean(r < 0),
      R2 = glue("$R^2 = {f_num(median(R2) * 100, digits = 0)}\\%$")
    ) %>% 
    mutate(
      p_kk = case_when(
        p_kk < .001 ~ "$\\Pr (r < 0) < 0.1\\%$",
        p_kk > .999 ~ "$\\Pr (r < 0) > 99.9\\%$",
        TRUE ~ paste0("$\\Pr (r < 0) = ", f_num(p_kk * 100, digits = 1), "\\%$")
      )
    ) %>% 
    ungroup()


```

First, we used meta-regression models to examine categorical moderator variables which we expected to explain heterogeneity in effect sizes across samples. As Figure 4 shows, we found that the setting of the study (`r with(R2, R2[moderator == "study_setting"])`), participants’ age group (`r with(R2, R2[moderator == "age"])`), and whether intergroup contact was measured directly or indirectly (`r with(R2, R2[moderator == "ic_direct"])`) explained the most variance across effect sizes. 

Second, we used meta-regression models to estimate effect sizes as a function of each country's cultural distance from the United States [@muthukrishna_beyond_2020]. Because cultural distance is a country-level moderator variable, we estimated random intercepts to account for both country-specific deviations from the mean effect size and sample-specific deviations from the country-specific effect size. As Figure 5 shows, we found that cultural distance from the United States tended to be associated with larger effect sizes—although we had data from too few countries to reach any firm conclusions. 

Third, we used meta-regression trees to discover interactions between moderator variables that best explained heterogeneity in effect sizes [@li_meta-cart_2017; @li_multiple_2020]. Figure 6 shows the resulting meta-regression model, which explained more variance across samples than any individual moderator (`r with(meta_cart, unique(R2))`). We found that intergroup contact was associated with less perceived injustice only in studies that measured direct, qualitatively positive contact among adults (`r with(meta_cart, r_kk[3])`) or in the few studies that did not measure direct, qualitatively positive contact but in which the groups’ relative inequality stemmed from short-term migration (`r with(meta_cart, r_kk[1])`).

## Meta Bias

```{=latex}
\begin{figure*}
\centering
\caption{Unadjusted ($\bullet$) and adjusted ($\circ$) point estimates with confidence intervals from the random-effects meta-analysis (RMA), the PET-PEESE estimator, the three-parameter selection model (3PSM), the \textit{p}-uniform* estimator, and the subgroup analysis}
\includegraphics[scale=1]{../figures/figure-7}
\label{fig:f7}
\end{figure*}
```

Developing methods to detect and correct for publication bias and other meta-biases is an active area of research, with no single method outperforming all others [@carter_correcting_2019]. Following Carter et al.’s recommendations, we compared results of several methods to adjust meta-analytic estimates for publication bias: the PET-PEESE estimator [@stanley_meta-regression_2014] adjusts meta-analytic estimates by correcting for the greater risk of smaller studies to not be published; the *p*-uniform* estimator [@van_aert_correcting_2018] adjusts meta-analytic estimates by correcting for the greater risk of non-significant effects to not be published; and the three-parameter selection model [3PSM, @vevea_general_1995] adjusts meta-analytic estimates for publication bias by estimating both the probability of a non-significant effect being published as well as the true average effect and between-study heterogeneity underlying the observed effect sizes.^[For an accessible introduction to meta bias correction, see @harrer_doing_2021.] 

In addition, we ran a subgroup analysis that included only studies that were not published or not conducted with the intention to examine the effects of intergroup contact on any of the outcomes—and that, therefore, can be assumed to have not been affected by publication bias. As the methods we used do not use Bayesian statistics, we compared adjusted estimates to unadjusted estimates from a random-effects meta-analysis estimated with restricted maximum likelihood estimation using the *metafor* R package [@viechtbauer_conducting_2010].

Figure 7 shows adjusted and unadjusted estimates with confidence intervals for the three outcomes. Comparing adjusted and unadjusted estimates shows that the PET-PEESE and 3PSM methods tended to estimate the mean correlation coefficients to be closer to zero than the unadjusted estimate, with all confidence intervals including zero. The *p*-uniform* method and the subgroup analysis tended to estimate the mean correlations coefficients to be closer to the unadjusted estimates, with the confidence interval for perceived injustice—but not for the other outcomes—excluding zero. All methods, however, resulted in confidence intervals that largely overlapped with, but were wider than, the confidence intervals around the unadjusted estimates. This reflects the reduced power of the various methods to correct for meta-biases when sample sizes are small, effect sizes are heterogeneous, or publication bias is strong [@carter_correcting_2019]. Therefore, we did not find evidence for publication bias—but also did not find conclusive evidence against it.

## Additional Analyses

```{=latex}
\begin{figure*}[t!]
\centering
\caption{Posterior distributions for studies that measured direct, qualitatively positive contact among adults}
\includegraphics[scale=1]{../figures/figure-8}
\caption*{\textit{Note.} Black outlines show the posterior distributions from the original, preregistered analyses. \textbf{A} Posterior distributions for the mean correlation coefficients, highlighting the proportion of posterior samples for which $r_\text{mean} < 0$. \textbf{B} Posterior predictive distributions of study-wise correlation coefficients, highlighting the 80\% most common effect sizes, with point estimates for the correlation coefficients for all studies in the sample.}
\label{fig:f8}
\end{figure*}
```

```{r, include = FALSE}

  # Import results from analyses
  pre_results <- read_rds("../results/results_preregistered_analyses.rds")
  add_results <- read_rds("../results/results_additional_analyses.rds")
  add_r_pred_jj <- read_rds("../results/r_additional_analyses_pred_jj.rds")
  
  # Merge results
  results <- add_results %>% 
    select(.chain:.draw, x_var, y_var, I, J, N, r_add = r_mean) %>% 
    left_join(
      pre_results %>% 
        select(.chain:.draw, x_var, y_var, r_pre = r_mean),
      by = c(".chain", ".iteration", ".draw", "x_var", "y_var")
    ) %>% 
    group_by(y_var) %>%
    summarize(
      I = f_comma(unique(I)),
      J = f_comma(unique(J)),
      N = f_comma(unique(N)),
      r_median = median(r_add),
      r_lower = quantile(r_add, 0.025),
      r_upper = quantile(r_add, 0.975),
      d_median = median(r_add - r_pre),
      d_lower = quantile(r_add - r_pre, 0.025),
      d_upper = quantile(r_add - r_pre, 0.975),
      p_below = mean(r_add < 0)
    ) %>% 
    left_join(
      add_r_pred_jj %>% 
        filter(x_var == "ic") %>% 
        group_by(y_var) %>% 
        summarize(p_pred = mean(r_pred > 0)),
      by = "y_var"
    ) %>% 
    mutate(
      across(
        c(starts_with("r_"), starts_with("d_")), 
        ~f_num(., digits = 2)
      ),
      r_text = paste0("$r = ", r_median, ", [", r_lower, ", ", r_upper, "]$"),
      d_text = paste0("$\\Delta r = ", d_median, ", [", d_lower, ", ", d_upper, "]$"),
      p_below = case_when(
        p_below < .001 ~ "$\\Pr (r < 0) < 0.1\\%$",
        p_below > .999 ~ "$\\Pr (r < 0) > 99.9\\%$",
        TRUE ~ paste0("$\\Pr (r < 0) = ", f_num(p_below * 100, digits = 1), "\\%$")
      ),
      p_pred = case_when(
        p_pred < .001 ~ "$< 0.1\\%$",
        p_pred > .999 ~ "$> 99.9\\%$",
        TRUE ~ paste0("$", f_num(p_pred * 100, digits = 1), "\\%$")
      )
    )

```

Our moderator analyses suggested that, for perceived injustice, the evidence for the 'ironic' effect of intergroup contact was stronger in studies that measured direct, qualitatively positive contact among adults than in most other studies. Operationalizing intergroup contact as direct, qualitatively positive contact among adults is closer to the original argument for the 'ironic' effects of intergroup contact and, therefore, tests a stronger case for the hypothesized relationships. To test this stronger case, we repeated our original, preregistered analyses for studies that measured direct, qualitatively positive contact among adults. 

Figure 8 shows posterior distributions from these analyses. Across `r with(results, N[y_var == "pi"])` participants from `r with(results, I[y_var == "pi"])` samples in `r with(results, J[y_var == "pi"])` studies, we found strong evidence for a small to medium negative association between intergroup contact and perceived injustice (`r with(results, r_text[y_var == "pi"])`), an effect size that is larger than estimated in the preregistered analysis (`r with(results, d_text[y_var == "pi"])`). Compared to the preregistered analyses, we did not find stronger associations with collective action (`r with(results, r_text[y_var == "ca"])`, `r with(results, d_text[y_var == "ca"])`) or policy support (`r with(results, r_text[y_var == "ps"])`, `r with(results, d_text[y_var == "ps"])`) in studies that measured direct, qualitatively positive contact among adults. These findings are not surprising as our preregistered analyses already prioritized predictor variables that measured direct, qualitatively positive contact and as most studies on collective action and policy support included those predictor variables. We estimated that `r with(results, p_pred[y_var == "pi"])`, `r with(results, p_pred[y_var == "ca"])`, and `r with(results, p_pred[y_var == "ps"])` of studies that measured direct, qualitatively positive contact among adults would find *positive* associations with perceived injustice, collective action, and policy support---suggesting that, relative to the preregistered analyses, focusing on direct, qualitatively positive contact among adults reduced the variance in effect sizes across studies.

## Alternative Explanations

```{r, include = FALSE}

  # Summarize results
  alt_results <- bind_rows(
      read_rds("../results/results_analyses_with_negative_contact.rds"),
      read_rds("../results/results_analyses_with_ingroup_contact.rds") 
    ) %>% 
    group_by(x_var, y_var) %>% 
    summarize(
      I = f_comma(unique(I)),
      J = f_comma(unique(J)),
      N = f_comma(unique(N)),
      median = median(r_mean),
      .lower = quantile(r_mean, 0.025),
      .upper = quantile(r_mean, 0.975),
      p_below = mean(r_mean < 0),
      p_above = mean(r_mean > 0)
    ) %>% 
    ungroup() %>% 
    mutate(
      across(
        c(median, .lower, .upper), 
        ~f_num(., digits = 2)
      ),
      p_below = case_when(
        p_below < .001 ~ "$\\Pr (r < 0) < 0.1\\%$",
        p_below > .999 ~ "$\\Pr (r < 0) > 99.9\\%$",
        TRUE ~ paste0("$\\Pr (r < 0) = ", f_num(p_below * 100, digits = 1), "\\%$")
      ),
      p_above = case_when(
        p_above < .001 ~ "$\\Pr (r > 0) < 0.1\\%$",
        p_above > .999 ~ "$\\Pr (r > 0) > 99.9\\%$",
        TRUE ~ paste0("$\\Pr (r > 0) = ", f_num(p_above * 100, digits = 1), "\\%$")
      ),
      p_text = case_when(
        x_var %in% c("nc", "ig") ~ p_above,
        x_var %in% c("pc", "og") ~ p_below
      ),
      r_text = paste0("$r = ", median, ", [", .lower, ", ", .upper, "]$"),
      text = paste(r_text, p_text, sep = "; ")
    ) %>% 
    select(-median, -.lower, -.upper)

```

```{=latex}
\begin{figure*}[t!]
\centering
\caption{Posterior distributions from the random-effects meta-analysis models with alternative predictor variables}
\includegraphics[scale=1]{../figures/figure-9}
\label{fig:f9}
\end{figure*}
```

We ran three random-effects meta-analysis models estimating the partial correlations of positive and negative contact with each outcome, using effect sizes from all studies that measured both predictors (Figure 9a). By using partial correlations, we estimated the effect of one form of contact while controlling for the other. Across `r alt_results$N[alt_results$x_var == "nc" & alt_results$y_var == "pi"]` participants from `r alt_results$I[alt_results$x_var == "nc" & alt_results$y_var == "pi"]` samples in `r alt_results$J[alt_results$x_var == "nc" & alt_results$y_var == "pi"]` studies, we found somewhat stronger evidence for a positive association between negative contact and perceived injustice (`r alt_results$text[alt_results$x_var == "nc" & alt_results$y_var == "pi"]`) than for a negative association between positive contact and perceived injustice (`r alt_results$text[alt_results$x_var == "pc" & alt_results$y_var == "pi"]`).  Across `r alt_results$N[alt_results$x_var == "nc" & alt_results$y_var == "ca"]` participants from `r alt_results$I[alt_results$x_var == "nc" & alt_results$y_var == "ca"]` samples in `r alt_results$J[alt_results$x_var == "nc" & alt_results$y_var == "ca"]` studies, we again found stronger evidence for a positive association between negative contact and collective action (`r alt_results$text[alt_results$x_var == "nc" & alt_results$y_var == "ca"]`) than for a negative association between positive contact and collective action (`r alt_results$text[alt_results$x_var == "pc" & alt_results$y_var == "ca"]`). Across `r alt_results$N[alt_results$x_var == "nc" & alt_results$y_var == "ps"]` participants from `r alt_results$I[alt_results$x_var == "nc" & alt_results$y_var == "ps"]` samples in `r alt_results$J[alt_results$x_var == "nc" & alt_results$y_var == "ps"]` studies, we also found stronger evidence for a positive association between negative contact and policy support (`r alt_results$text[alt_results$x_var == "nc" & alt_results$y_var == "ps"]`) than for a negative association between positive contact and policy support (`r alt_results$text[alt_results$x_var == "pc" & alt_results$y_var == "ps"]`). Across `r alt_results$N[alt_results$x_var == "pc" & alt_results$y_var == "nc"]` participants from `r alt_results$I[alt_results$x_var == "pc" & alt_results$y_var == "nc"]` samples in `r alt_results$J[alt_results$x_var == "pc" & alt_results$y_var == "nc"]` studies, we found a negative association between positive and negative contact (`r alt_results$text[alt_results$x_var == "pc" & alt_results$y_var == "nc"]`).

We ran three random-effects meta-analysis models that estimated the partial correlations of ingroup and outgroup contact with each outcome, using effect sizes from all studies that measured both predictors (Figure 9b). Across `r alt_results$N[alt_results$x_var == "ig" & alt_results$y_var == "pi"]` participants from `r alt_results$I[alt_results$x_var == "ig" & alt_results$y_var == "pi"]` samples in `r alt_results$J[alt_results$x_var == "ig" & alt_results$y_var == "pi"]` studies, we found insufficient evidence for associations of ingroup contact (`r alt_results$text[alt_results$x_var == "ig" & alt_results$y_var == "pi"]`) and outgroup contact (`r alt_results$text[alt_results$x_var == "og" & alt_results$y_var == "pi"]`) with perceived injustice. Across `r alt_results$N[alt_results$x_var == "ig" & alt_results$y_var == "ca"]` participants from `r alt_results$I[alt_results$x_var == "ig" & alt_results$y_var == "ca"]` samples in `r alt_results$J[alt_results$x_var == "ig" & alt_results$y_var == "ca"]` studies, we found stronger evidence for a positive association between ingroup contact and collective action (`r alt_results$text[alt_results$x_var == "ig" & alt_results$y_var == "ca"]`) than for a negative association between outgroup contact and collective action (`r alt_results$text[alt_results$x_var == "og" & alt_results$y_var == "ca"]`). Across `r alt_results$N[alt_results$x_var == "ig" & alt_results$y_var == "ps"]` participants from `r alt_results$I[alt_results$x_var == "ig" & alt_results$y_var == "ps"]` samples in `r alt_results$J[alt_results$x_var == "ig" & alt_results$y_var == "ps"]` study, we found insufficient evidence for associations of ingroup contact (`r alt_results$text[alt_results$x_var == "ig" & alt_results$y_var == "ps"]`) and outgroup contact (`r alt_results$text[alt_results$x_var == "og" & alt_results$y_var == "ps"]`) with policy support. Across `r alt_results$N[alt_results$x_var == "ig" & alt_results$y_var == "og"]` participants from `r alt_results$I[alt_results$x_var == "ig" & alt_results$y_var == "og"]` samples in `r alt_results$J[alt_results$x_var == "ig" & alt_results$y_var == "og"]` studies, we found a positive association between ingroup and outgroup contact (`r alt_results$text[alt_results$x_var == "ig" & alt_results$y_var == "og"]`).

# Discussion

```{r, include = FALSE}

  # Set seed (for posterior predictive simulations)
  set.seed(9071118)

  # Summarize results
  summary <- read_rds("../results/results_preregistered_analyses.rds") %>% 
    filter(x_var == "ic", y_var %in% c("pi", "ca", "ps")) %>% 
    mutate(
      r_pred = z_to_r(rnorm(n = n(), mean = mu, sd = tau_jj))
    ) %>% 
    group_by(x_var, y_var) %>% 
    summarize(
      r = median(r_mean),
      p = mean(r_mean < 0),
      r_lower = quantile(r_mean, 0.025),
      r_upper = quantile(r_mean, 0.975),
      p_pred_positive = mean(r_pred > 0)
    ) %>% 
    ungroup() %>% 
    mutate(
      r_text = paste0("$r = ", f_num(r, digits = 2), "$"),
      p_text = case_when(
        p < .001 ~ "$\\Pr (r < 0) < 0.1\\%$",
        p > .999 ~ "$\\Pr (r < 0) > 99.9\\%$",
        TRUE ~ paste0("$\\Pr (r < 0) = ", f_num(p * 100, digits = 1), "\\%$")
      )
    )

```

There is an emerging consensus that intergroup contact has the 'ironic' effect of undermining support for social change in disadvantaged groups. We conducted a preregistered meta-analytic test of this effect across `r with(dplyr::distinct(readRDS("../data/dl.rds"), sample, id, n), numform::f_comma(dplyr::n_distinct(id)))` studies with `r with(dplyr::distinct(readRDS("../data/dl.rds"), sample, id, n), numform::f_comma(length(sample)))` samples of `r with(dplyr::distinct(readRDS("../data/dl.rds"), sample, id, n), numform::f_comma(sum(n)))` disadvantaged-group members. We found that, based on the available evidence, the associations of intergroup contact with perceived injustice (`r with(summary, p_text[y_var == "pi"])`), collective action (`r with(summary, p_text[y_var == "ca"])`), and support for reparative policies (`r with(summary, p_text[y_var == "ps"])`) were, on average, much more likely to be negative than positive. Thus, our meta-analysis seems to support the emerging consensus. However, our findings qualify this conclusion in several important ways.

First, the estimated effect sizes for the average associations of intergroup contact with perceived injustice (`r with(summary, r_text[y_var == "pi"])`), collective action (`r with(summary, r_text[y_var == "ca"])`), and policy support (`r with(summary, r_text[y_var == "ps"])`) were small. Across the three outcomes, the 95% most plausible estimates included effect sizes between `r paste0("$r = ", f_num(min(summary$r_lower), digits = 2), "$")` and `r paste0("$r = ", f_num(max(summary$r_upper), digits = 2), "$")`. Effect sizes were thus much smaller than for the association between contact and prejudice in minority ($r = -.18$) and majority ($r = -.23$) groups [@tropp_relationships_2005].^[Comparing standardized effect sizes assumes that the two outcomes are of equal importance. That is not always the case: for example, a drug that reduces mild symptoms by 0.20 standard deviations is not necessarily better than a drug that reduces deaths by 0.10 standard deviations.] Small effects can still be important if they accumulate over time or across people. For example, even a small change in policy attitudes could, if it affects enough people, sway a tight election. Cumulative effects, however, should not be assumed without an empirical or theoretical rationale [@funder_evaluating_2019].

Second, the estimated effect sizes varied across studies. For example, we estimated that `r f_prop2percent(with(summary, p_pred_positive[y_var == "pi"]), digits = 0)` of studies find a positive association between intergroup contact and perceived injustice. While the between-study heterogeneity is comparable to that in other meta-analyses [e.g., @pettigrew_meta-analytic_2006], it supports Pettigrew et al.'s [-@pettigrew_recent_2011] argument that, at least in some circumstances, intergroup contact renders discrimination *more* salient.

A combination of moderators explained about a third of the between-study variance in the association between intergroup contact and perceived injustice. We found the most consistent evidence for a negative association in studies that measured direct, qualitatively positive contact among adults (e.g., by asking how much time they spent with friends from the advantaged outgroup). This operationalization is closely aligned with, and thus supports, the original argument for the ‘ironic’ effects of intergroup contact. More broadly, this finding suggests that the magnitude and direction of the observed effects depends on how intergroup contact is measured. Like other measures of social psychological constructs [@flake_construct_2017], few measures of intergroup contact resulted from a systematic process of scale development [for an exception, see @hayward_toward_2017] or underwent a rigorous process of scale validation [for an overview, see @lolliot_measures_2015]. Although we did not find conclusive evidence for systematic cultural differences in the 'ironic' effects of intergroup contact, we found that, like other areas of psychological research [@henrich_weirdest_2010], this area of research continues to underrepresent large parts of Africa, Asia, and South America. Future research should systematically investigate how contact affects support for social change across different measures, settings, and cultures.

Third, the available evidence is almost entirely from cross-sectional, correlational studies and thus consistent with alternative explanations for the observed associations. Support for social change could reduce intergroup contact rather than the other way around. For example, disadvantaged-group members involved in collective action might avoid forming friendships with advantaged-group members. Alternatively, the observed associations could be spurious with both being caused by an unobserved confounder. For example, a disadvantaged-group member's socioeconomic status might both expose them to more advantaged-group members and reduce their perception of injustice. Future research should prioritize longitudinal studies to confirm the direction of the observed associations and (field) experiments to rule out confounding and other alternative explanations.^[Published research includes only three longitudinal studies [@401; @956; @1743], all of which conflated within-person change and between-person stability [@hamaker_critique_2015], two experimental studies with a no-contact control condition [@2075; @2033], and two intervention studies [@2399; @789].]

Fourth, the observed association between intergroup contact and support for social change could be confounded by an alternative predictor that *increases* support for social change. Supporting Reimer et al.'s [-@956] argument, we found that positive intergroup contact was not associated with support for social change after controlling for negative contact which, in turn, was associated with *greater* support for social change. We found mixed evidence for ingroup contact as an alternative explanation for the 'ironic' effects of intergroup contact [@sengupta_ingroup_2015] but note that few studies measured both ingroup and outgroup contact. Going forward, researchers should clarify which aspects of intergroup contact should theoretically affect support for social change—and include measures that allow testing both the hypothesized and competing explanations.

Considering positive and negative contact helps us understand both the *reality* of contact as experienced in everyday interactions as well as the *ideal* of contact as targeted in planned interventions. When considering contact in planned interventions designed to promote positive contact, our findings suggest that contact-based interventions could reduce awareness of, and opposition to, social injustice in disadvantaged groups. This finding is consistent with the argument that intergroup contact, as a strategy to reduce prejudice, is in conflict with collective action as a strategy to effect social change [@dixon_beyond_2012; @dixon_models_2012]. Future research on contact-based interventions should consider strategies to resolve this conflict [e.g., @2075; @2033; @hassler_need_2021; @rodriguez_engaging_2018]. When considering contact in everyday interactions, our findings suggest that negative experiences, not positive, experiences with the advantaged affect support for social change among the disadvantaged. This finding is consistent with the argument that negative contact draws attention to the discrimination disadvantaged-group members faces and strengthens their resolve to challenge social injustice [see @956]. While theoretical and methodological questions remain in the study of negative contact [@schafer_does_2021], future research should measure both forms of contact to avoid confounding the presence of positive contact with the absence of negative contact.

Finally, we cannot rule out that biases in the literature caused our meta-analysis to overestimate the 'ironic' effects of intergroup contact. Publication bias could have prevented studies that found positive or non-significant associations from entering the published literature. We used various methods to detect and correct for publication bias, yet did not find conclusive evidence for or against publication bias. That said, 61% of samples were either not collected with the intention to study the effects of intergroup contact on a relevant outcome (45%) or from unpublished studies (32%)—and thus unlikely to have been affected by publication bias. Another bias that could have affected our findings is that researchers made data-dependent decisions while collecting and analyzing data that are known to inflate false-positive findings [@gelman_statistical_2014; @simmons_false-positive_2011]. This risk is pertinent to a literature in which most studies are correlational, include many measures, and are not preregistered—and, therefore, do not constrain the direction of observed associations or the selection of included variables. Future research should use preregistration and other methods to prevent undisclosed flexibility in data collection and analysis.

Our research was motivated by the broader question whether intergroup contact helps or hinders social change. By examining the narrower question whether intergroup contact diminishes support for social change in disadvantaged groups, we tested the most prominent hypotheses explaining how intergroup contact might *hinder* social change. We did not consider whether intergroup contact might also *help* social change by reducing prejudice [for critical perspectives, see @dixon_beyond_2012; @jackman_velvet_1994] or by motivating the advantaged to acknowledge and challenge social inequality [@tropp_making_2018]. Likewise, we did not test whether, in certain conditions, positive contact with advantaged-group members might *increase* support for social change in disadvantaged groups. For example, studies found positive intergroup contact to increase collective action intentions when advantaged-group members acknowledged intergroup injustice as illegitimate [@2075] or expressed support for social change [@2033]. More broadly, intergroup contact is associated with more support for social change if it satisfies disadvantaged-group members' need for empowerment, that is, when they felt that the advantaged-group members they had contact with listened to what they had to say and perceived them as competent and intelligent [@hassler_need_2021].^[We did not consider whether, in certain conditions, positive contact might increase support for social change in disadvantaged groups because only few studies measured the relevant moderator variables and because our analyses relied on correlation matrices which are not enough to estimate interaction effects. For the latter reason, we also did not consider whether positive and negative contact might interact in their effects on support for social change [see @albzour_talking_2022].] Further, we did not consider contact between different disadvantaged groups, which has been found to increase support for social change among the disadvantaged [@dixon_divide_2015; @93]. Therefore, this meta-analysis could not provide a complete answer to the question whether, on balance, intergroup contact helps or hinders social change.

To conclude, our preregistered meta-analysis found some evidence that intergroup contact reduces perceived injustice, discourages collective action, and diminishes support for reparative policies in disadvantaged groups—but also showed that the estimated effect sizes were small, variable, and consistent with alternative explanations. Future research should (1) compare the direction and magnitude of the associations between intergroup contact and support for social change across cultures, groups, and issues; (2) use longitudinal designs and field experiments to establish the direction of these relationships and to rule out spurious associations; (3) include validated measures that allow testing alternative explanations for the apparent 'ironic' effects of intergroup contact; and (4) incorporate practices to prevent undisclosed flexibility in data collection and analysis. We hope that our meta-analysis helps researchers to address the open questions about how intergroup contact relates to support for social change in disadvantaged groups.

\refsection

References marked with an asterisk are studies included in the meta-analysis.

\begingroup

\noindent
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}
\small

<div id="refs"></div>

\endgroup
