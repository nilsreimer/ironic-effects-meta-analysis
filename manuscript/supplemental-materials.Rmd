---
title: "Supplemental Online Materials"
subtitle: Meta-Analysis of the 'Ironic' Effects of Intergroup Contact
bibliography: references.bib
output:
  pdf_document:
    latex_engine: pdflatex
    keep_tex: yes
    template: som-template.tex
csl: apa.csl
---

```{r setup, include = FALSE}

  # Load packages
  library(tidyverse); library(tidybayes); library(numform)

  # Functions
  r_to_z <- function(r) 0.5 * log( (1 + r) / (1 - r) )
  z_to_r <- function(z) ( exp(2 * z) - 1 ) / ( exp(2 * z) + 1 )

  # knitr options
  knitr::opts_chunk$set(echo = FALSE)

```

## Deviations 

We preregistered the eligibility criteria, search strategy, study selection, data collection, and preregistered analyses. Some aspects of the preregistered protocol proved unrealistic, impractical, or underspecified. Therefore, we deviated from the protocol in the following ways:

1. We preregistered that we would update our search every four months until we would submit the manuscript. This proved unrealistic as the study selection and data collection process for the new studies took almost as long. Instead, we concluded our search of electronic databases on April 1, 2020—that is, before we started analyzing and documenting our findings.

2. We preregistered that we would randomly select 100 records to be screened by both coders to calculate inter-rater agreement. We did not specify, however, what we would do if inter-rater agreement was less than acceptable. We decided to refine our coding strategy over three samples of 100 records until we achieved acceptable agreement.

3. We preregistered that we would use *Google Scholar* to find records citing eligible studies. This proved impractical as *Google Scholar* does not facilitate the electronic export of citing records. Instead, we used the *Scopus* citation database.

4. We preregistered that we would attempt to contact the authors of all papers with missing effect sizes. Instead, we decided to not contact authors for studies published before 2000 as we considered it unlikely that the authors still had access to the data.

5. We preregistered that we would use a Bayesian two-level random-effects meta-analysis model, described in the main text, for all preregistered analyses. For the association between policy support and collective action, however, we had only few studies and found that the two-level model did not result in a reliable posterior distribution (as indicated by divergent transitions in the estimation algorithm). Instead, we used a Bayesian one-level random-effects model to estimate that association.

## Search Strategy

We used similar non-exclusive search terms for all electronic databases:

1. (contact OR friendship) AND (“perceived discrimination” OR “perceived \*advantage” OR “relative deprivation” OR “group discrimination” OR “personal discrimination” OR “group deprivation” OR “perception\* of discrimination” OR “perception* of group discrimination” OR “perception* of personal discrimination” OR “rac\* discrimination”)

2. \*group AND (contact OR friendship) AND (“collective action” OR protest OR “collective behavio\*r” OR “political behavio\*r” OR “social change” OR “social justice”)

3. \*group AND (contact OR friendship) AND (policy OR policies OR “affirmative action” OR (politi* W/15 attitude\*) OR (politi\* W/15 preferenc\*)) AND (redistribut\* OR reparati\* OR inequalit\* OR equalit\* OR injustice\* OR justice\* OR disadvantage\* OR advantage\* OR minorit\* OR majorit\*)

\noindent We sent a call for unpublished research to the mailing lists of the *European Association of Social Psychology*, the *Society for Personality and Social Psychology*, the *International Society of Political Psychology*, the *Society for the Psychological Study of Social Issues*, and the *Society of Australasian Social Psychologists*.

## Moderator Analyses

First, we ran a series of Bayesian random-effects meta-regression models to estimate how much of the between-samples heterogeneity was explained by specific categorical moderator variables (`run_moderator_analyses.R`). Figures S1 and S2 show the results for collective action and policy support. Comparisons were inconclusive because we had an insufficient number of effect sizes per category. Second, we ran another three random-effects meta-regression models with Muthukrishna et al.'s [-@muthukrishna_beyond_2020] measure of cultural distance, where available, as a continuous moderator variable. Because cultural distance was a country-level moderator variable, we used two-level random-effects models in which we estimated country-specific deviations from the mean effect size as well as sample-specific deviations from the country-specific effect size. Figure 5 (in the main text) show the inconclusive results for all three outcomes. 

Second, we used meta-regression trees to discover interactions between moderator variables that best explained heterogeneity in effect sizes [@li_meta-cart_2017]. As recommended, we ran random-effects meta-regression tree analyses using the look-ahead strategy [@li_multiple_2020]. We set the pruning parameter to $c = 0$ because, for this analysis, we prioritized exploration over error control (`run_exploratory_moderator_analyses.R`). For both collective action and policy support, the algorithm found that no moderator or interaction of moderators explained between-samples heterogeneity. This result is not surprising, however, as both analyses used fewer than 40 effect sizes, the minimum number required for the algorithm to perform well in detecting even simple interaction effects [@li_meta-cart_2017]. As all moderator analyses were inconclusive for collective action and policy support, we only report results for perceived injustice in the main text.

```{=latex}
\begin{figure*}
\centering
\caption{Estimated effect sizes for the association between intergroup contact and collective action as a function of various categorical moderator variables}
\includegraphics[scale=1]{../figures/figure-s1}
\caption*{\textit{Note.} Intervals enclose the 95\% most plausible estimates of the category-specific effect size. Shaded ribbons enclose the 95\% most plausible estimates of the mean effect size from the main analyses. Percentages indicate the estimated between-sample variance explained by each moderator variable.}
\label{fig:s1}
\end{figure*}

\begin{figure*}
\centering
\caption{Estimated effect sizes for the association between intergroup contact and policy support as a function of various categorical moderator variables}
\includegraphics[scale=1]{../figures/figure-s2}
\caption*{\textit{Note.} Intervals enclose the 95\% most plausible estimates of the category-specific effect size. Shaded ribbons enclose the 95\% most plausible estimates of the mean effect size from the main analyses. Percentages indicate the estimated between-sample variance explained by each moderator variable.}
\label{fig:s2}
\end{figure*}
```

# References

\begingroup

\noindent
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id="refs"></div>

\endgroup

